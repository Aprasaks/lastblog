// src/app/api/chat/route.js
import { NextResponse } from 'next/server'
import OpenAI from 'openai'
import fs from 'fs'
import path from 'path'
import matter from 'gray-matter'

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
})

// ë‚´ í¬ìŠ¤íŠ¸ë“¤ ê°€ì ¸ì˜¤ê¸°
function getMyPosts() {
  try {
    const postsDir = path.join(process.cwd(), 'src', 'posts')
    const filenames = fs.readdirSync(postsDir).filter(f => f.endsWith('.md'))
    
    return filenames.map(filename => {
      const filePath = path.join(postsDir, filename)
      const source = fs.readFileSync(filePath, 'utf8')
      const { data, content } = matter(source)
      
      return {
        id: filename.replace(/\.md$/, ''),
        title: data.title || filename.replace(/\.md$/, ''),
        category: data.category || 'ê¸°íƒ€',
        content: content.slice(0, 1000) // ì²˜ìŒ 1000ìë§Œ
      }
    })
  } catch (error) {
    console.error('Error reading posts:', error)
    return []
  }
}

export async function POST(request) {
  try {
    const { message } = await request.json()
    
    // ë‚´ í¬ìŠ¤íŠ¸ë“¤ ê°€ì ¸ì˜¤ê¸°
    const myPosts = getMyPosts()
    
    // ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
    const systemPrompt = `ë‹¹ì‹ ì€ DEMIANì˜ ê°œì¸ ë¸”ë¡œê·¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ JARVISì…ë‹ˆë‹¤.

ê·œì¹™:
1. ë‹µë³€ì€ 2-3ì¤„ ì´ë‚´ë¡œ ê°„ë‹¨í•˜ê²Œ í•˜ì„¸ìš”
2. ê¸°ìˆ  ê´€ë ¨ ì§ˆë¬¸: ë¬¸ì„œê°€ ìˆìœ¼ë©´ "ì œëª©ì´ 'XXX'ì¸ í¬ìŠ¤íŠ¸ê°€ ìˆìŠµë‹ˆë‹¤" í˜•ì‹ìœ¼ë¡œ ë‹µë³€
3. ì¼ìƒ ëŒ€í™”: ì¹œê·¼í•˜ê²Œ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ì„¸ìš”
4. ë¬¸ì„œì— ì—†ëŠ” ê¸°ìˆ  ì§ˆë¬¸: "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"

ì‚¬ìš© ê°€ëŠ¥í•œ DEMIANì˜ ë¬¸ì„œë“¤:
${myPosts.map(post => `ì œëª©: ${post.title}, ì¹´í…Œê³ ë¦¬: ${post.category}`).join('\n')}

ë‹µë³€ ì˜ˆì‹œ:
- ê¸°ìˆ : "mapì— ê´€í•œ 'ë¹„ë™ê¸° í•¨ìˆ˜' ë¬¸ì„œê°€ ìˆìŠµë‹ˆë‹¤"
- ì¼ìƒ: "ì ì‹¬ì€ ê¹€ì¹˜ì°Œê°œ ì–´ë– ì„¸ìš”? ë”°ëœ»í•˜ê³  ë§›ìˆì–´ìš”!"
- ì¼ìƒ: "ëª¨ë“  ë¶„ë“¤ì´ ê°ìì˜ ë§¤ë ¥ì´ ìˆì–´ì„œ ë¹„êµí•˜ê¸° ì–´ë ¤ì›Œìš” ğŸ˜Š"
`

    // OpenAI API í˜¸ì¶œ
    const completion = await openai.chat.completions.create({
      model: "gpt-3.5-turbo",
      messages: [
        { role: "system", content: systemPrompt },
        { role: "user", content: message }
      ],
      max_tokens: 500,
      temperature: 0.7,
    })

    const aiResponse = completion.choices[0].message.content

    // ê²€ìƒ‰ëœ í¬ìŠ¤íŠ¸ë“¤ ì°¾ê¸° (í‚¤ì›Œë“œ ê¸°ë°˜)
    const searchResults = myPosts.filter(post => 
      message.toLowerCase().split(' ').some(word => 
        post.title.toLowerCase().includes(word) || 
        post.content.toLowerCase().includes(word) ||
        post.category.toLowerCase().includes(word)
      )
    ).slice(0, 3) // ìµœëŒ€ 3ê°œë§Œ

    return NextResponse.json({ 
      response: aiResponse,
      searchResults: searchResults
    })

  } catch (error) {
    console.error('OpenAI API Error:', error)
    
    // ì—ëŸ¬ ì‹œ ê¸°ë³¸ ì‘ë‹µ
    const fallbackResponse = "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì¼ì‹œì ì¸ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
    
    return NextResponse.json({ 
      response: fallbackResponse,
      searchResults: []
    })
  }
}